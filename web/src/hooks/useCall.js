import { useState, useRef, useEffect, useCallback } from 'react';
import { socket, reconnectSocket } from '../utils/socket';
import SimplePeer from 'simple-peer';
import { API_BASE_URL } from '../config/api';
import { toast } from 'react-toastify';
import { getAuthToken } from '../utils/auth';
import { useSoundEffects } from '../components/SoundEffects';

// STUN servers for WebRTC
// Default STUN servers as fallback
const DEFAULT_ICE_SERVERS = [
  { urls: 'stun:stun.l.google.com:19302' },
  { urls: 'stun:stun1.l.google.com:19302' }
];

// Helper to fetch TURN credentials securely
const fetchIceServers = async () => {
  try {
    const token = getAuthToken();
    if (!token) return DEFAULT_ICE_SERVERS;

    const response = await fetch(`${API_BASE_URL}/api/turn-credentials`, {
      headers: { 'Authorization': `Bearer ${token}` }
    });

    if (response.ok) {
      const data = await response.json();
      return data.iceServers || DEFAULT_ICE_SERVERS;
    }
    return DEFAULT_ICE_SERVERS;
  } catch (error) {
    console.warn('Failed to fetch TURN credentials, falling back to STUN:', error);
    return DEFAULT_ICE_SERVERS;
  }
};

export const useCall = () => {
  // Sound effects for call tones
  const { playCalling, playRingtone, playEndCall, stopCalling, stopRingtone } = useSoundEffects();

  const [callState, setCallState] = useState(null); // null, 'initiating', 'ringing', 'active', 'ended'
  const [incomingCall, setIncomingCall] = useState(null);
  const [localStream, setLocalStream] = useState(null);
  const [remoteStream, setRemoteStream] = useState(null);
  const [isMuted, setIsMuted] = useState(false);
  const [isVideoEnabled, setIsVideoEnabled] = useState(true);
  const [remoteIsMuted, setRemoteIsMuted] = useState(false); // Remote mute status
  const [remoteVideoEnabled, setRemoteVideoEnabled] = useState(true); // Remote video status
  const [callDuration, setCallDuration] = useState(0);
  const [activeCall, setActiveCall] = useState(null); // { callId, appointmentId, receiverId, callType }
  const [availableCameras, setAvailableCameras] = useState([]);
  const [currentCameraId, setCurrentCameraId] = useState(null);
  const [isScreenSharing, setIsScreenSharing] = useState(false);
  const [remoteIsScreenSharing, setRemoteIsScreenSharing] = useState(false); // Track if remote is screen sharing
  const [cameraStreamDuringScreenShare, setCameraStreamDuringScreenShare] = useState(null); // Camera stream for small window during screen share
  const [isFullscreen, setIsFullscreen] = useState(false);
  const [connectionQuality, setConnectionQuality] = useState('good'); // 'excellent', 'good', 'fair', 'poor'
  const [availableMicrophones, setAvailableMicrophones] = useState([]);
  const [availableSpeakers, setAvailableSpeakers] = useState([]);
  const [currentMicrophoneId, setCurrentMicrophoneId] = useState(null);
  const [currentSpeakerId, setCurrentSpeakerId] = useState(null);

  const peerRef = useRef(null);
  const localVideoRef = useRef(null);
  const remoteVideoRef = useRef(null);
  const remoteAudioRef = useRef(null); // For audio calls
  const callStartTimeRef = useRef(null);
  const durationIntervalRef = useRef(null);
  const animationFrameRef = useRef(null);
  const lastSecondRef = useRef(null);
  const pendingOfferRef = useRef(null); // Store offer if received before peer is created
  const screenShareStreamRef = useRef(null); // Store screen share stream
  const originalCameraStreamRef = useRef(null); // Store original camera stream before screen share
  const containerRef = useRef(null); // For fullscreen
  const callingSoundRef = useRef(null); // Reference to calling sound audio element
  const ringtoneSoundRef = useRef(null); // Reference to ringtone sound audio element
  const isEndingCallRef = useRef(false); // Flag to prevent double end call sound

  // Refs to store current state for event handlers (to avoid stale closures)
  const incomingCallRef = useRef(null);
  const activeCallRef = useRef(null);
  const callStateRef = useRef(null);
  const localStreamRef = useRef(null); // Ref for localStream to access in monitor peer handlers

  // Admin monitor peers: Map of adminSocketId -> SimplePeer instance
  const monitorPeersRef = useRef(new Map());

  // Update refs when state changes (so handlers can access current values)
  useEffect(() => {
    incomingCallRef.current = incomingCall;
    activeCallRef.current = activeCall;
    callStateRef.current = callState;
    localStreamRef.current = localStream;
  }, [incomingCall, activeCall, callState, localStream]);

  // Handle WebRTC offer
  const handleWebRTCOffer = useCallback(({ callId, offer }) => {
    // If peer doesn't exist yet (receiver), store the offer
    if (!peerRef.current) {
      // Only store if it matches incoming call
      if (incomingCallRef.current?.callId === callId || activeCallRef.current?.callId === callId) {
        pendingOfferRef.current = { callId, offer };
      }
      return;
    }

    if (activeCallRef.current?.callId !== callId) {
      return;
    }

    try {
      peerRef.current.signal(offer);
    } catch (error) {
      console.error('[Call] Error handling WebRTC offer:', error);
    }
  }, []);

  // Handle WebRTC answer
  const handleWebRTCAnswer = useCallback(({ callId, answer }) => {
    if (!peerRef.current) {
      return;
    }

    if (activeCallRef.current?.callId !== callId) {
      return;
    }

    try {
      peerRef.current.signal(answer);
    } catch (error) {
      console.error('[Call] Error handling WebRTC answer:', error);
    }
  }, []);

  // Handle ICE candidate
  const handleICECandidate = useCallback(({ callId, candidate }) => {
    if (!peerRef.current) {
      return;
    }

    if (activeCallRef.current?.callId !== callId) {
      return;
    }

    try {
      if (candidate) {
        peerRef.current.signal(candidate);
      }
    } catch (error) {
      console.error('[Call] Error handling ICE candidate:', error);
    }
  }, []);

  // Handle remote mute/video status updates
  const handleRemoteStatusUpdate = useCallback(({ callId, isMuted: remoteMuted, isVideoEnabled: remoteVideo, isScreenSharing: remoteScreenSharing }) => {
    if (activeCall?.callId === callId) {
      if (remoteMuted !== undefined) setRemoteIsMuted(remoteMuted);
      if (remoteVideo !== undefined) setRemoteVideoEnabled(remoteVideo);
      if (remoteScreenSharing !== undefined) setRemoteIsScreenSharing(remoteScreenSharing);
    }
  }, [activeCall]);

  // Handle request to stop screen sharing (when remote person wants to share)
  const handleStopRemoteScreenShare = useCallback(() => {
    if (isScreenSharing) {
      // Stop screen sharing when remote requests it
      if (screenShareStreamRef.current) {
        screenShareStreamRef.current.getTracks().forEach(track => track.stop());
        screenShareStreamRef.current = null;
      }
      setIsScreenSharing(false);
      setCameraStreamDuringScreenShare(null);

      // Restore camera video in peer connection
      if (localStream && peerRef.current && originalCameraStreamRef.current) {
        const originalVideoTrack = originalCameraStreamRef.current.getVideoTracks()[0];
        if (originalVideoTrack) {
          const sender = peerRef.current._pc.getSenders().find(s =>
            s.track && s.track.kind === 'video'
          );
          if (sender && peerRef.current) {
            sender.replaceTrack(originalVideoTrack).catch(err => {
              console.error('Error restoring camera track:', err);
            });
          }
        }
      }
      toast.info('Screen sharing stopped - other person is now sharing');
    }
  }, [isScreenSharing, localStream]);

  // Maintain local stream on localVideoRef whenever it changes
  useEffect(() => {
    if (!localStream || !localVideoRef.current) return;

    // Only update if stream is different (avoid unnecessary updates)
    if (localVideoRef.current.srcObject !== localStream) {
      localVideoRef.current.srcObject = localStream;
      localVideoRef.current.muted = true; // Local video should always be muted

      // Ensure video plays
      const playVideo = async () => {
        try {
          await localVideoRef.current.play();
        } catch (err) {
          console.error('Error playing local video:', err);
          // Retry after a short delay
          setTimeout(() => {
            localVideoRef.current?.play().catch(e => {
              console.error('Retry failed:', e);
            });
          }, 500);
        }
      };
      playVideo();
    }
  }, [localStream, localVideoRef]);

  // Attach remote stream to video/audio elements when stream or call type changes
  useEffect(() => {
    if (!remoteStream || !activeCall) {
      // Clean up when stream or call ends
      if (remoteVideoRef.current) {
        remoteVideoRef.current.srcObject = null;
      }
      if (remoteAudioRef.current) {
        remoteAudioRef.current.srcObject = null;
      }
      setRemoteIsScreenSharing(false);
      return;
    }

    // Detect if remote is screen sharing by checking video track label
    // Check for enabled tracks with screen share labels (enabled = true means track is actively streaming)
    const videoTracks = remoteStream.getVideoTracks();
    const isRemoteScreenSharing = videoTracks.some(track =>
      track.enabled && track.label && (track.label.includes('screen') || track.label.includes('Screen') || track.label.includes('display'))
    );

    // Update remote screen sharing state
    setRemoteIsScreenSharing(isRemoteScreenSharing);

    // When remote switches from screen share to camera, force UI update
    // This helps with the rendering issue when screen share stops on remote side
    if (!isRemoteScreenSharing && remoteVideoRef.current) {
      // Force the ref to update by briefly setting to null then back
      setTimeout(() => {
        if (remoteVideoRef.current && remoteVideoRef.current.srcObject === remoteStream) {
          remoteVideoRef.current.srcObject = null;
          setTimeout(() => {
            if (remoteVideoRef.current) {
              remoteVideoRef.current.srcObject = remoteStream;
              remoteVideoRef.current.play().catch(err => {
                console.error('Error playing remote video after screen share detection:', err);
              });
            }
          }, 50);
        }
      }, 50);
    }

    // For video calls - attach to video element (video element handles both video and audio)
    if (activeCall.callType === 'video' && remoteVideoRef.current) {
      // Only update if stream is different (avoid unnecessary updates)
      if (remoteVideoRef.current.srcObject !== remoteStream) {
        // Clear previous stream
        if (remoteVideoRef.current.srcObject) {
          remoteVideoRef.current.srcObject.getTracks().forEach(track => track.stop());
        }
        remoteVideoRef.current.srcObject = remoteStream;
        remoteVideoRef.current.muted = false; // Ensure audio is not muted
        // Ensure video plays
        const playVideo = async () => {
          try {
            await remoteVideoRef.current.play();
          } catch (err) {
            console.error('Error playing remote video:', err);
            // Retry after a short delay
            setTimeout(() => {
              remoteVideoRef.current?.play().catch(e => {
                console.error('Retry failed:', e);
              });
            }, 500);
          }
        };
        playVideo();
      }
    }

    // For audio calls - attach to audio element
    if (activeCall.callType === 'audio' && remoteAudioRef.current) {
      // Only update if stream is different (avoid unnecessary updates)
      if (remoteAudioRef.current.srcObject !== remoteStream) {
        // Clear previous stream
        if (remoteAudioRef.current.srcObject) {
          remoteAudioRef.current.srcObject.getTracks().forEach(track => track.stop());
        }
        remoteAudioRef.current.srcObject = remoteStream;
        remoteAudioRef.current.muted = false; // Ensure audio is not muted
        // Ensure audio plays automatically
        const playAudio = async () => {
          try {
            await remoteAudioRef.current.play();
          } catch (err) {
            console.error('Error playing remote audio:', err);
            // Retry after a short delay
            setTimeout(() => {
              if (remoteAudioRef.current) {
                remoteAudioRef.current.play().catch(e => {
                  console.error('Retry failed:', e);
                });
              }
            }, 500);
          }
        };
        playAudio();
      }
    }

    // Cleanup function
    return () => {
      if (!activeCall && remoteStream) {
        remoteStream.getTracks().forEach(track => track.stop());
      }
    };
  }, [remoteStream, activeCall]);

  // Start call timer with server-synchronized start time
  // CRITICAL: This function MUST be called with server's startTime to ensure both sides are synchronized
  // Start call timer with server-synchronized start time
  // CRITICAL: This function MUST be called with server's startTime to ensure both sides are synchronized
  const startCallTimer = useCallback((synchronizedStartTime) => {
    if (!synchronizedStartTime) {
      console.error('[Call Timer] ERROR: Cannot start timer without server startTime!');
      return;
    }

    // Stop any existing timers
    if (durationIntervalRef.current) {
      clearInterval(durationIntervalRef.current);
      durationIntervalRef.current = null;
    }
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    // Use the exact server start time as the reference point
    // Both sides will use this same timestamp, ensuring perfect synchronization
    const serverStartTimestamp = synchronizedStartTime.getTime();

    // Calculate initial elapsed time to display immediately (accounts for network latency)
    const currentTimestamp = Date.now();
    const elapsedMilliseconds = currentTimestamp - serverStartTimestamp;

    // UX IMPROVEMENT: If elapsed time is small (e.g. < 3000ms), assume it's a fresh call 
    // and sync to local time for better UX. This prevents the timer from jumping to 00:02 
    // immediately due to network latency, ensuring both sides see "00:00" start.
    if (elapsedMilliseconds < 3000 && elapsedMilliseconds >= 0) {
      callStartTimeRef.current = currentTimestamp;
    } else {
      callStartTimeRef.current = serverStartTimestamp;
    }

    lastSecondRef.current = null;

    // Set initial duration immediately
    const initialDuration = Math.max(0, Math.floor((Date.now() - callStartTimeRef.current) / 1000));
    setCallDuration(initialDuration);
    lastSecondRef.current = initialDuration;

    // Use requestAnimationFrame for smooth, precise updates
    // Calculate duration from server timestamp each frame, ensuring no drift
    const updateTimer = () => {
      if (!callStartTimeRef.current) {
        return;
      }

      // Always calculate from server's startTime - this ensures perfect synchronization
      // Even if intervals drift, both sides calculate from the same reference point
      const now = Date.now();
      // Use Math.max(0, ...) to prevent negative durations due to clock skew
      // If server time is slightly ahead of client time, ensure duration starts at 0
      const duration = Math.max(0, Math.floor((now - callStartTimeRef.current) / 1000));

      // Only update state when the second changes to avoid unnecessary re-renders
      if (duration !== lastSecondRef.current) {
        lastSecondRef.current = duration;
        setCallDuration(duration);
      }

      // Continue animation loop
      animationFrameRef.current = requestAnimationFrame(updateTimer);
    };

    // Start the animation frame loop immediately for instant updates
    // This ensures the timer starts ticking right away, not waiting for the first frame
    animationFrameRef.current = requestAnimationFrame(updateTimer);

    // Also use interval as backup for reliability, but start immediately with a small delay
    // This ensures the timer ticks immediately rather than waiting up to 1000ms
    const immediateUpdate = () => {
      if (callStartTimeRef.current) {
        const now = Date.now();
        const duration = Math.max(0, Math.floor((now - callStartTimeRef.current) / 1000));
        if (duration !== lastSecondRef.current) {
          lastSecondRef.current = duration;
          setCallDuration(duration);
        }
      }
    };

    // Trigger immediate update to ensure timer starts ticking right away
    immediateUpdate();

    // Then set up interval for regular updates (every 1000ms)
    durationIntervalRef.current = setInterval(() => {
      if (callStartTimeRef.current) {
        // Always calculate from server's startTime, not local time
        // This double-check ensures accuracy even if animation frame is delayed
        // Use Math.max(0, ...) to prevent negative durations due to clock skew
        const duration = Math.max(0, Math.floor((Date.now() - callStartTimeRef.current) / 1000));
        if (duration !== lastSecondRef.current) {
          lastSecondRef.current = duration;
          setCallDuration(duration);
        }
      }
    }, 1000);
  }, []);

  // Listen for incoming calls and WebRTC events
  useEffect(() => {
    const handleIncomingCall = (data) => {
      // Prevent handling new incoming call if already in a call or receiving one
      if (activeCallRef.current || incomingCallRef.current || callStateRef.current) {
        console.warn('Blocking concurrent incoming call:', data.callId);
        // Optionally emit 'busy' back to server if needed, but server should handle this.
        return;
      }

      setIncomingCall(data);
      // Play ringtone when receiving incoming call
      stopCalling(); // Stop any calling sound that might be playing
      ringtoneSoundRef.current = playRingtone();
    };

    const handleCallAccepted = (data) => {
      // Server provides the exact timestamp when call was accepted on the server
      // Both caller and receiver receive this same timestamp, ensuring perfect synchronization
      // startTime is sent as milliseconds (number) from server, convert to Date object
      const synchronizedStartTime = data.startTime ? new Date(data.startTime) : null;

      if (!synchronizedStartTime || !data.startTime) {
        console.error('[Call] CRITICAL: No synchronized startTime received from server! Cannot start timer.');
        toast.error('Call timer synchronization error. Please refresh.');
        return;
      }

      // For receiver (incoming call) - state already set in acceptCall, but timer MUST start with server time
      // Use refs to get current values without causing dependency issues
      if (incomingCallRef.current && incomingCallRef.current.callId === data.callId) {
        // Stop ringtone when call is accepted
        stopRingtone();
        ringtoneSoundRef.current = null;

        // Force immediate state update
        setCallState('active');

        // Always start/restart timer with server's synchronized time
        // This ensures timer starts at the exact same moment as on server, accounting for network latency
        startCallTimer(synchronizedStartTime);
      }
      // For caller (outgoing call)
      else if (activeCallRef.current && activeCallRef.current.callId === data.callId) {
        // Stop calling sound when call is accepted
        stopCalling();
        callingSoundRef.current = null;

        // Force immediate state update
        setCallState('active');

        // CRITICAL: Only start timer with server's startTime - never use local time
        startCallTimer(synchronizedStartTime);
      }
    };

    const handleCallRejected = (data) => {
      // Use ref to get current value without dependency
      if (activeCallRef.current && activeCallRef.current.callId === data.callId) {
        // Stop calling sound when call is rejected
        stopCalling();
        callingSoundRef.current = null;
        endCall();
        toast.info('Call was rejected');
      }
      // Stop ringtone when call is rejected (receiver side)
      if (incomingCallRef.current && incomingCallRef.current.callId === data.callId) {
        stopRingtone();
        ringtoneSoundRef.current = null;
      }
    };

    const handleCallEnded = (data) => {
      // Use refs to get current values without dependency
      if ((activeCallRef.current && activeCallRef.current.callId === data.callId) ||
        (incomingCallRef.current && incomingCallRef.current.callId === data.callId)) {
        // Stop any playing sounds
        stopCalling();
        stopRingtone();
        callingSoundRef.current = null;
        ringtoneSoundRef.current = null;
        // Only play end call sound if we didn't just end the call ourselves
        // (to prevent double playing when user clicks hang and server broadcasts back)
        if (!isEndingCallRef.current) {
          playEndCall();
        }
        // Show "Call ended" message when receiving call-ended event from other party
        toast.info('Call ended.');
        endCall();
      }
    };

    const handleCallMissed = (data) => {
      // Use ref to get current value without dependency
      if (activeCallRef.current && activeCallRef.current.callId === data.callId) {
        // Stop calling sound when call is missed
        stopCalling();
        callingSoundRef.current = null;
        endCall();
        toast.info('Call was missed');
      }
      // Stop ringtone when call is missed (receiver side)
      if (incomingCallRef.current && incomingCallRef.current.callId === data.callId) {
        stopRingtone();
        ringtoneSoundRef.current = null;
      }
    };

    const handleCallCancelled = (data) => {
      // When caller cancels, receiver should close incoming call modal
      // Use refs to get current values without dependency
      if (incomingCallRef.current && incomingCallRef.current.callId === data.callId) {
        // Stop ringtone when call is cancelled
        stopRingtone();
        ringtoneSoundRef.current = null;
        setIncomingCall(null);
        // Don't call endCall here to avoid double cleanup, just clear incoming call state
        setCallState(null);
        setActiveCall(null);
        toast.info('Call was cancelled');
      }
      // When caller cancels, caller should close ringing screen
      if (activeCallRef.current && activeCallRef.current.callId === data.callId &&
        (callStateRef.current === 'ringing' || callStateRef.current === 'initiating')) {
        // Stop calling sound when call is cancelled
        stopCalling();
        callingSoundRef.current = null;
        // endCall was already called, just ensure state is cleared
        setCallState(null);
        setActiveCall(null);
        toast.info('Call cancelled');
      }
    };

    socket.on('incoming-call', handleIncomingCall);
    socket.on('call-accepted', handleCallAccepted);
    socket.on('call-rejected', handleCallRejected);
    socket.on('call-ended', handleCallEnded);
    socket.on('call-missed', handleCallMissed);
    socket.on('call-cancelled', handleCallCancelled);
    socket.on('webrtc-offer', handleWebRTCOffer);
    socket.on('webrtc-answer', handleWebRTCAnswer);
    socket.on('ice-candidate', handleICECandidate);
    socket.on('remote-status-update', handleRemoteStatusUpdate);
    socket.on('stop-remote-screen-share', handleStopRemoteScreenShare);
    socket.on('call-error', (error) => {
      console.error('Call error:', error);
      toast.error(error.message || 'Call error occurred');
      endCall();
    });

    // ===== Admin Monitor Request Handler (Participant Side) =====
    // When admin wants to monitor, we create a separate peer that sends our localStream to them
    const handleAdminMonitorRequest = async ({ callId, adminSocketId }) => {
      try {
        if (!activeCallRef.current || activeCallRef.current.callId !== callId) {
          return;
        }
        if (!localStreamRef.current) {
          console.warn('[Monitor] No local stream available for admin monitor');
          return;
        }

        // Create a monitor peer as initiator (we send offer to admin)
        const monitorPeer = new SimplePeer({
          initiator: true,
          trickle: true,
          stream: localStreamRef.current, // Send our local stream to admin
          config: {
            iceServers: await fetchIceServers()
          }
        });

        monitorPeer.on('signal', (data) => {
          if (data.type === 'offer') {
            socket.emit('webrtc-offer-monitor', {
              callId,
              adminSocketId,
              offer: data
            });
          } else if (data.type === 'candidate') {
            socket.emit('ice-candidate-monitor', {
              callId,
              adminSocketId,
              candidate: data,
              from: 'participant'
            });
          }
        });

        monitorPeer.on('connect', () => {
          console.log('[Monitor] Connected to admin monitor peer');
        });

        monitorPeer.on('error', (err) => {
          console.error('[Monitor] Peer error:', err);
          monitorPeersRef.current.delete(adminSocketId);
        });

        monitorPeer.on('close', () => {
          console.log('[Monitor] Peer closed');
          monitorPeersRef.current.delete(adminSocketId);
        });

        monitorPeersRef.current.set(adminSocketId, monitorPeer);
      } catch (err) {
        console.error('[Monitor] Error creating admin monitor peer:', err);
      }
    };

    // Admin answers our monitor offer
    const handleWebRTCAnswerMonitor = ({ callId, adminSocketId, answer }) => {
      if (!activeCallRef.current || activeCallRef.current.callId !== callId) return;
      const monitorPeer = monitorPeersRef.current.get(adminSocketId);
      if (monitorPeer && answer) {
        try {
          monitorPeer.signal(answer);
        } catch (err) {
          console.error('[Monitor] Error signaling answer to monitor peer:', err);
        }
      }
    };

    // Admin sends ICE candidates for monitor connection
    const handleICECandidateMonitor = ({ callId, adminSocketId, candidate }) => {
      if (!activeCallRef.current || activeCallRef.current.callId !== callId) return;
      const monitorPeer = monitorPeersRef.current.get(adminSocketId);
      if (monitorPeer && candidate) {
        try {
          monitorPeer.signal(candidate);
        } catch (err) {
          console.error('[Monitor] Error signaling ICE candidate to monitor peer:', err);
        }
      }
    };

    socket.on('admin-monitor-request', handleAdminMonitorRequest);
    socket.on('webrtc-answer-monitor', handleWebRTCAnswerMonitor);
    socket.on('ice-candidate-monitor', handleICECandidateMonitor);

    return () => {
      socket.off('incoming-call', handleIncomingCall);
      socket.off('call-accepted', handleCallAccepted);
      socket.off('call-rejected', handleCallRejected);
      socket.off('call-ended', handleCallEnded);
      socket.off('call-missed', handleCallMissed);
      socket.off('call-cancelled', handleCallCancelled);
      socket.off('webrtc-offer', handleWebRTCOffer);
      socket.off('webrtc-answer', handleWebRTCAnswer);
      socket.off('ice-candidate', handleICECandidate);
      socket.off('remote-status-update', handleRemoteStatusUpdate);
      socket.off('stop-remote-screen-share', handleStopRemoteScreenShare);
      socket.off('call-error');
      socket.off('admin-monitor-request');
      socket.off('webrtc-answer-monitor');
      socket.off('ice-candidate-monitor');
    };
  }, [handleWebRTCOffer, handleWebRTCAnswer, handleICECandidate, handleRemoteStatusUpdate, handleStopRemoteScreenShare, startCallTimer]);

  // Enumerate available cameras
  const enumerateCameras = useCallback(async () => {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter(device => device.kind === 'videoinput');
      setAvailableCameras(videoDevices);
      if (videoDevices.length > 0 && !currentCameraId) {
        setCurrentCameraId(videoDevices[0].deviceId);
      }
      return videoDevices;
    } catch (error) {
      console.error('Error enumerating cameras:', error);
      return [];
    }
  }, [currentCameraId]);

  // Switch camera
  const switchCamera = useCallback(async (deviceId) => {
    if (!localStream || !activeCall || activeCall.callType !== 'video') {
      return;
    }

    try {
      // Get new stream with selected camera
      const newStream = await navigator.mediaDevices.getUserMedia({
        audio: true,
        video: { deviceId: { exact: deviceId } }
      });

      // Replace video track in peer connection
      const videoTrack = newStream.getVideoTracks()[0];
      const sender = peerRef.current?._pc?.getSenders()?.find(s =>
        s.track && s.track.kind === 'video'
      );

      if (sender && videoTrack) {
        await sender.replaceTrack(videoTrack);
      }

      // Update local stream
      const oldVideoTrack = localStream.getVideoTracks()[0];
      if (oldVideoTrack) {
        oldVideoTrack.stop();
      }
      localStream.removeTrack(oldVideoTrack);
      localStream.addTrack(videoTrack);

      // Update video element
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = localStream;
      }

      setCurrentCameraId(deviceId);
      toast.success('Camera switched');
    } catch (error) {
      console.error('Error switching camera:', error);
      toast.error('Failed to switch camera');
    }
  }, [localStream, activeCall]);

  // Initialize call
  const initiateCall = async (appointmentId, receiverId, callType) => {
    try {
      // Check if socket is connected
      if (!socket || !socket.connected) {
        const token = getAuthToken();
        if (!token) {
          toast.error('Please sign in to make calls.');
          return;
        }

        try {
          const parts = token.split('.');
          if (parts.length === 3) {
            const payload = JSON.parse(atob(parts[1]));
            const currentTime = Date.now() / 1000;
            if (payload.exp && payload.exp < currentTime) {
              toast.error('Your session has expired. Please sign in again.');
              localStorage.removeItem('accessToken');
              document.cookie = 'access_token=; Max-Age=0; path=/; SameSite=None; Secure';
              window.location.href = '/sign-in?error=session_expired';
              return;
            }
          }
        } catch (e) {
          console.warn('Token validation failed:', e);
        }

        reconnectSocket();
        toast.info('Reconnecting to server...');
        await new Promise(resolve => setTimeout(resolve, 1000));
        if (!socket || !socket.connected) {
          toast.error('Failed to connect to server. Please refresh the page or sign in again.');
          return;
        }
      }

      setCallState('initiating');

      // Enumerate cameras for video calls
      if (callType === 'video') {
        await enumerateCameras();
      }

      // Get user media
      const constraints = {
        audio: true,
        video: callType === 'video' ? (currentCameraId ? { deviceId: { exact: currentCameraId } } : true) : false
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);

      setLocalStream(stream);
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
      }

      // Wait for call ID from server before creating peer connection
      const handleCallInitiated = ({ callId, status }) => {
        if (status === 'ringing') {
          setActiveCall({ callId, appointmentId, receiverId, callType });
          setCallState('ringing');
          // Play calling sound when call is ringing
          callingSoundRef.current = playCalling();

          // Create peer connection AFTER we have the callId
          // Fetch ICE servers first
          fetchIceServers().then((iceServers) => {
            const peer = new SimplePeer({
              initiator: true,
              trickle: true,
              stream: stream, // SimplePeer will automatically add stream tracks
              config: {
                iceServers: iceServers
              }
            });

            // Track peer connection state changes
            if (peer._pc) {
              peer._pc.addEventListener('track', (event) => {
                if (event.streams && event.streams[0]) {
                  setRemoteStream(event.streams[0]);
                }
              });
            }

            peer.on('signal', (data) => {
              if (data.type === 'offer') {
                socket.emit('webrtc-offer', {
                  callId: callId,
                  offer: data
                });
              } else if (data.type === 'candidate') {
                socket.emit('ice-candidate', {
                  callId: callId,
                  candidate: data
                });
              }
            });

            peer.on('stream', (remoteStream) => {
              setRemoteStream(remoteStream);
              // Stream attachment will be handled by useEffect when remoteStream state updates
            });

            peer.on('connect', () => {
              // Connection established
            });

            peer.on('error', (err) => {
              // Silence specific errors during intentional teardown or aborts
              if (isEndingCallRef.current || (err.message && (err.message.includes('Abort') || err.message.includes('Close called')))) {
                return;
              }
              console.error('Peer connection error:', err);
              // Only end call if connection fails completely and no stream
              if (!remoteStream) {
                toast.error('Connection failed');
                endCall();
              }
            });

            peerRef.current = peer;
          });
        }
      };

      socket.once('call-initiated', handleCallInitiated);

      // Emit call initiation
      socket.emit('call-initiate', {
        appointmentId,
        receiverId,
        callType
      });

    } catch (error) {
      console.error('Error initiating call:', error);
      setCallState(null);
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        toast.error('Microphone/camera permission denied. Please allow access in your browser settings.');
      } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
        toast.error('No microphone/camera found. Please connect a device.');
      } else {
        toast.error('Failed to access microphone/camera. Please check permissions.');
      }
      throw error;
    }
  };

  // Accept incoming call
  const acceptCall = async () => {
    if (!incomingCall) return;

    try {
      // Enumerate cameras for video calls
      if (incomingCall.callType === 'video') {
        await enumerateCameras();
      }

      const constraints = {
        audio: true,
        video: incomingCall.callType === 'video' ? (currentCameraId ? { deviceId: { exact: currentCameraId } } : true) : false
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);

      setLocalStream(stream);
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
      }

      // Update localStreamRef immediately for cleanup purposes
      localStreamRef.current = stream;

      // Fetch ICE servers first
      fetchIceServers().then((iceServers) => {
        const peer = new SimplePeer({
          initiator: false,
          trickle: true,
          stream: stream, // SimplePeer will automatically add stream tracks
          config: {
            iceServers: iceServers
          }
        });

        // Track peer connection state changes
        if (peer._pc) {
          peer._pc.addEventListener('track', (event) => {
            if (event.streams && event.streams[0]) {
              setRemoteStream(event.streams[0]);
            }
          });
        }

        peer.on('signal', (data) => {
          if (data.type === 'answer') {
            socket.emit('webrtc-answer', {
              callId: incomingCall.callId,
              answer: data
            });
          } else if (data.type === 'candidate') {
            socket.emit('ice-candidate', {
              callId: incomingCall.callId,
              candidate: data
            });
          }
        });

        peer.on('stream', (remoteStream) => {
          setRemoteStream(remoteStream);
          // Stream attachment will be handled by useEffect when remoteStream state updates
        });

        peer.on('connect', () => {
          // Connection established
        });

        peer.on('error', (err) => {
          // Silence specific errors during intentional teardown or aborts
          if (isEndingCallRef.current || (err.message && (err.message.includes('Abort') || err.message.includes('Close called')))) {
            return;
          }
          console.error('Peer connection error:', err);
          toast.error('Connection error occurred');
          endCall();
        });

        // If we have a pending offer, signal it now
        if (pendingOfferRef.current && pendingOfferRef.current.callId === incomingCall.callId) {
          peer.signal(pendingOfferRef.current.offer);
          pendingOfferRef.current = null;
        }

        peerRef.current = peer;

        // Emit call accept AFTER peer is created
        socket.emit('call-accept', { callId: incomingCall.callId });
      });

      setActiveCall({
        callId: incomingCall.callId,
        appointmentId: incomingCall.appointmentId,
        receiverId: incomingCall.callerId,
        callType: incomingCall.callType
      });

      // Stop ringtone immediately when call is accepted (don't wait for server response)
      stopRingtone();
      ringtoneSoundRef.current = null;

      setCallState('active');
      setIncomingCall(null);
      // Timer will be started by handleCallAccepted with synchronized time from server
    } catch (error) {
      console.error('Error accepting call:', error);
      toast.error('Failed to access microphone/camera. Please check permissions.');

      // Stop tracks manually if stream was created but setup failed
      // This handles the case where setLocalStream state update hasn't propagated yet
      // and endCall relies on state.
      // Note: We can't easily access 'stream' here if declared in try block,
      // but since we set localStreamRef.current, we can use that via endCall if we ensure likely
      // availability or clean up what we can.
      rejectCall();
    }
  };

  // Reject call
  const rejectCall = () => {
    // Stop ringtone when rejecting call
    stopRingtone();
    ringtoneSoundRef.current = null;
    // Play end call sound when rejecting call
    playEndCall();
    if (incomingCall) {
      socket.emit('call-reject', { callId: incomingCall.callId });
      setIncomingCall(null);
    }
    endCall();
  };

  // End call
  const endCall = async () => {
    // Set flag to prevent double end call sound
    const wasEndingCall = isEndingCallRef.current;
    isEndingCallRef.current = true;

    // Stop all sounds first
    stopCalling();
    stopRingtone();
    callingSoundRef.current = null;
    ringtoneSoundRef.current = null;

    // Cancel call first if still initiating/ringing (before clearing state)
    if (activeCall?.callId && (callState === 'initiating' || callState === 'ringing')) {
      socket.emit('call-cancel', { callId: activeCall.callId });
    }

    // Stop local stream
    // Stop local stream
    // Check both state variable and ref to ensure we catch stream even if state update is pending
    const streamToStop = localStream || localStreamRef.current;
    if (streamToStop) {
      streamToStop.getTracks().forEach(track => {
        track.stop();
        track.enabled = false; // Explicitly disable to ensure indicator goes off
      });
      setLocalStream(null);
      localStreamRef.current = null;
    }

    // Stop remote stream
    if (remoteStream) {
      remoteStream.getTracks().forEach(track => track.stop());
      setRemoteStream(null);
    }

    // Clear remote audio/video refs
    if (remoteVideoRef.current) {
      remoteVideoRef.current.srcObject = null;
    }
    if (remoteAudioRef.current) {
      remoteAudioRef.current.srcObject = null;
    }

    // Destroy peer connection
    if (peerRef.current) {
      peerRef.current.destroy();
      peerRef.current = null;
    }

    // Destroy all monitor peers
    if (monitorPeersRef.current.size > 0) {
      monitorPeersRef.current.forEach((peer) => {
        try {
          peer.destroy();
        } catch (err) {
          console.error('[Monitor] Error destroying monitor peer:', err);
        }
      });
      monitorPeersRef.current.clear();
    }

    // Stop all timers
    if (durationIntervalRef.current) {
      clearInterval(durationIntervalRef.current);
      durationIntervalRef.current = null;
    }
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    callStartTimeRef.current = null;
    lastSecondRef.current = null;

    // Notify backend if call was active (not just ringing)
    if (activeCall?.callId && callState === 'active') {
      try {
        await fetch(`${API_BASE_URL}/api/calls/end`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          credentials: 'include',
          body: JSON.stringify({ callId: activeCall.callId })
        });

        // Ensure screen share is stopped if active
        if (screenShareStreamRef.current) {
          screenShareStreamRef.current.getTracks().forEach(track => track.stop());
          screenShareStreamRef.current = null;
        }
        if (isScreenSharing) {
          setIsScreenSharing(false);
        }

        // Play end call sound when user ends the call
        // Only play if this is the first time ending (not from handleCallEnded)
        if (!wasEndingCall) {
          playEndCall();
        }
        // Show "Call ended" message when user ends the call
        toast.info('Call ended.');
      } catch (error) {
        console.error('Error ending call on server:', error);
        // Still play sound and show message even if backend call fails
        // Only play if this is the first time ending (not from handleCallEnded)
        if (!wasEndingCall) {
          playEndCall();
        }
        toast.info('Call ended.');
      }
    } else if (activeCall?.callId || incomingCall?.callId) {
      // Play end call sound even if call wasn't active yet (ringing/incoming state)
      if (!wasEndingCall) {
        playEndCall();
      }
      toast.info('Call ended.');
    }

    // Force clear all call-related state immediately
    setCallState(null);
    setCallDuration(0);
    callStartTimeRef.current = null;
    setActiveCall(null);
    setIncomingCall(null);
    pendingOfferRef.current = null;

    setRemoteIsMuted(false);
    setRemoteVideoEnabled(true);
    setIsScreenSharing(false);
    setRemoteIsScreenSharing(false);

    // Sync refs immediately to prevent race conditions
    activeCallRef.current = null;
    incomingCallRef.current = null;
    callStateRef.current = null;

    // Reset flag after a short delay to allow for cleanup
    setTimeout(() => {
      isEndingCallRef.current = false;
    }, 1000);
  };

  // Toggle mute
  const toggleMute = () => {
    if (localStream) {
      const newMutedState = !isMuted;
      // When muted, track.enabled should be false (disabled)
      // When unmuted, track.enabled should be true (enabled)
      localStream.getAudioTracks().forEach(track => {
        track.enabled = !newMutedState; // Opposite: muted = disabled, unmuted = enabled
      });
      setIsMuted(newMutedState);

      // Notify remote peer
      if (activeCall?.callId) {
        socket.emit('call-status-update', {
          callId: activeCall.callId,
          isMuted: newMutedState,
          isVideoEnabled: isVideoEnabled
        });
      }
    }
  };

  // Toggle video
  const toggleVideo = () => {
    if (localStream) {
      const newVideoState = !isVideoEnabled;
      localStream.getVideoTracks().forEach(track => {
        track.enabled = newVideoState;
      });
      setIsVideoEnabled(newVideoState);

      // Notify remote peer
      if (activeCall?.callId) {
        socket.emit('call-status-update', {
          callId: activeCall.callId,
          isMuted: isMuted,
          isVideoEnabled: newVideoState
        });
      }
    }
  };

  // Toggle screen sharing (video calls only)
  const toggleScreenShare = async () => {
    // Check for screen sharing support
    if (!navigator.mediaDevices || !navigator.mediaDevices.getDisplayMedia) {
      toast.error('Screen sharing is not supported on this device or browser (common on mobile).');
      return;
    }

    try {
      if (!isScreenSharing) {
        // Check if remote is already screen sharing
        if (remoteIsScreenSharing) {
          // Ask user for confirmation
          const confirmed = window.confirm(
            'Other person is also sharing. Are you sure you want to share yours? (This will stop their screen share)'
          );

          if (!confirmed) {
            return; // User cancelled
          }

          // Notify remote to stop screen sharing
          if (activeCall?.callId) {
            socket.emit('stop-remote-screen-share', {
              callId: activeCall.callId
            });
          }
        }

        // Start screen sharing
        // First, store the original camera stream for the small "You" window
        if (localStream) {
          const originalVideoTrack = localStream.getVideoTracks()[0];
          if (originalVideoTrack) {
            // Create a new stream with the original camera track for the small window
            // We only need the video track for display in the small window
            const originalCameraStream = new MediaStream([originalVideoTrack]);
            originalCameraStreamRef.current = originalCameraStream;
            setCameraStreamDuringScreenShare(originalCameraStream);
          }
        }

        const screenStream = await navigator.mediaDevices.getDisplayMedia({
          video: { cursor: 'always' },
          audio: true
        });

        screenShareStreamRef.current = screenStream;
        setIsScreenSharing(true);

        if (activeCall?.callId) {
          socket.emit('call-status-update', {
            callId: activeCall.callId,
            isMuted: isMuted,
            isVideoEnabled: isVideoEnabled,
            isScreenSharing: true
          });
        }

        // Update monitor peers (Admin)
        if (monitorPeersRef.current.size > 0) {
          const videoTracks = screenStream.getVideoTracks();
          if (videoTracks.length > 0) {
            monitorPeersRef.current.forEach((monitorPeer) => {
              try {
                // Send status update via data channel
                monitorPeer.send(JSON.stringify({ type: 'status-update', isScreenSharing: true }));

                // Replace video track
                const sender = monitorPeer._pc.getSenders().find(s => s.track && s.track.kind === 'video');
                if (sender) {
                  sender.replaceTrack(videoTracks[0]);
                }
              } catch (err) {
                console.error('Error updating monitor peer with screen share:', err);
              }
            });
          }
        }

        // Replace video track in peer connection (send screen share to remote)
        if (localStream && peerRef.current) {
          const videoTracks = screenStream.getVideoTracks();
          const audioTracks = screenStream.getAudioTracks();

          // Replace video track in peer connection
          if (videoTracks.length > 0) {
            const sender = peerRef.current._pc.getSenders().find(s =>
              s.track && s.track.kind === 'video'
            );
            if (sender) {
              await sender.replaceTrack(videoTracks[0]);
            }
          }

          // Replace audio track if available (screen share audio)
          if (audioTracks.length > 0) {
            const sender = peerRef.current._pc.getSenders().find(s =>
              s.track && s.track.kind === 'audio'
            );
            if (sender && !isMuted) {
              await sender.replaceTrack(audioTracks[0]);
            }
          }
        }

        // Stop screen sharing when user stops sharing from browser UI
        screenStream.getVideoTracks()[0].onended = () => {
          // Don't call toggleScreenShare to avoid showing dialog again
          // Instead, just handle stopping directly
          if (screenShareStreamRef.current) {
            screenShareStreamRef.current.getTracks().forEach(track => track.stop());
            screenShareStreamRef.current = null;
          }
          setIsScreenSharing(false);

          if (activeCall?.callId) {
            socket.emit('call-status-update', {
              callId: activeCall.callId,
              isMuted: isMuted,
              isVideoEnabled: isVideoEnabled,
              isScreenSharing: false
            });
          }

          // Restore monitor peers (Admin)
          if (monitorPeersRef.current.size > 0 && originalCameraStreamRef.current) {
            const originalVideoTrack = originalCameraStreamRef.current.getVideoTracks()[0];
            if (originalVideoTrack) {
              monitorPeersRef.current.forEach((monitorPeer) => {
                try {
                  monitorPeer.send(JSON.stringify({ type: 'status-update', isScreenSharing: false }));
                  const sender = monitorPeer._pc.getSenders().find(s => s.track && s.track.kind === 'video');
                  if (sender) {
                    sender.replaceTrack(originalVideoTrack);
                  }
                } catch (err) {
                  console.error('Error restoring monitor peer track:', err);
                }
              });
            }
          }

          // Restore camera video in peer connection
          if (localStream && peerRef.current && originalCameraStreamRef.current) {
            const originalVideoTrack = originalCameraStreamRef.current.getVideoTracks()[0];
            if (originalVideoTrack) {
              const sender = peerRef.current._pc.getSenders().find(s =>
                s.track && s.track.kind === 'video'
              );
              if (sender && peerRef.current) {
                sender.replaceTrack(originalVideoTrack).catch(err => {
                  console.error('Error restoring camera track:', err);
                });
              }
            }
          }
          setCameraStreamDuringScreenShare(null);
          toast.info('Screen sharing stopped');
        };

        toast.success('Screen sharing started');
      } else {
        // Stop screen sharing
        if (screenShareStreamRef.current) {
          screenShareStreamRef.current.getTracks().forEach(track => track.stop());
          screenShareStreamRef.current = null;
        }

        setIsScreenSharing(false);

        if (activeCall?.callId) {
          socket.emit('call-status-update', {
            callId: activeCall.callId,
            isMuted: isMuted,
            isVideoEnabled: isVideoEnabled,
            isScreenSharing: false
          });
        }

        // Restore monitor peers (Admin)
        if (monitorPeersRef.current.size > 0 && originalCameraStreamRef.current) {
          const originalVideoTrack = originalCameraStreamRef.current.getVideoTracks()[0];
          if (originalVideoTrack) {
            monitorPeersRef.current.forEach((monitorPeer) => {
              try {
                monitorPeer.send(JSON.stringify({ type: 'status-update', isScreenSharing: false }));
                const sender = monitorPeer._pc.getSenders().find(s => s.track && s.track.kind === 'video');
                if (sender) {
                  sender.replaceTrack(originalVideoTrack);
                }
              } catch (err) {
                console.error('Error restoring monitor peer track:', err);
              }
            });
          }
        }

        // Restore camera video in peer connection
        if (localStream && peerRef.current && originalCameraStreamRef.current) {
          const originalVideoTrack = originalCameraStreamRef.current.getVideoTracks()[0];
          const originalAudioTrack = localStream.getAudioTracks()[0]; // Use original audio from localStream

          if (originalVideoTrack) {
            const sender = peerRef.current._pc.getSenders().find(s =>
              s.track && s.track.kind === 'video'
            );

            if (sender && peerRef.current) {
              await sender.replaceTrack(originalVideoTrack);
            }
          }

          // Restore original audio track
          if (originalAudioTrack) {
            const sender = peerRef.current._pc.getSenders().find(s =>
              s.track && s.track.kind === 'audio'
            );
            if (sender && !isMuted) {
              await sender.replaceTrack(originalAudioTrack);
            }
          }

          // Clean up original camera stream ref - BUT DO NOT STOP TRACKS
          // The tracks in originalCameraStreamRef are references to the tracks in localStream.
          // Stopping them here would revoke camera access. We just null the ref.
          originalCameraStreamRef.current = null;
          setCameraStreamDuringScreenShare(null);

          // Force update local video element to show camera again
          if (localVideoRef.current && localStream) {
            // Re-attach the local stream to ensure video shows
            const currentSrcObject = localVideoRef.current.srcObject;
            if (currentSrcObject) {
              // Remove screen share tracks if any
              currentSrcObject.getTracks().forEach(track => {
                if (track.kind === 'video' && track.label.includes('screen')) {
                  track.stop();
                }
              });
            }
            // Ensure local stream is attached
            localVideoRef.current.srcObject = localStream;
            localVideoRef.current.muted = true;
            localVideoRef.current.play().catch(err => {
              console.error('Error playing local video after screen share:', err);
            });
          }

          // Also force refresh the remote stream display when local stops sharing
          // This ensures the other party's video shows up again in the large view
          if (remoteVideoRef.current && remoteStream) {
            setTimeout(() => {
              if (remoteVideoRef.current && remoteVideoRef.current.srcObject === remoteStream) {
                // Force refresh by temporarily unsetting and resetting
                remoteVideoRef.current.srcObject = null;
                setTimeout(() => {
                  if (remoteVideoRef.current) {
                    remoteVideoRef.current.srcObject = remoteStream;
                    remoteVideoRef.current.muted = false;
                    remoteVideoRef.current.play().catch(err => {
                      console.error('Error playing remote video after local screen share stops:', err);
                    });
                  }
                }, 50);
              }
            }, 50);
          }
        } else if (localStream && callType === 'video' && currentCameraId) {
          // Fallback: recreate camera stream if original not stored
          const cameraStream = await navigator.mediaDevices.getUserMedia({
            video: { deviceId: { exact: currentCameraId } },
            audio: true
          });

          const videoTrack = cameraStream.getVideoTracks()[0];
          const audioTrack = cameraStream.getAudioTracks()[0];
          const sender = peerRef.current?._pc?.getSenders()?.find(s =>
            s.track && s.track.kind === 'video'
          );

          if (sender && peerRef.current) {
            await sender.replaceTrack(videoTrack);
          }

          // Restore audio
          const audioSender = peerRef.current?._pc?.getSenders()?.find(s =>
            s.track && s.track.kind === 'audio'
          );
          if (audioSender && audioTrack && !isMuted) {
            await audioSender.replaceTrack(audioTrack);
          }

          // Update local stream
          localStream.getVideoTracks().forEach(track => track.stop());
          localStream.addTrack(videoTrack);

          // Update local video element
          if (localVideoRef.current) {
            localVideoRef.current.srcObject = localStream;
            localVideoRef.current.muted = true;
            localVideoRef.current.play().catch(err => {
              console.error('Error playing local video after screen share:', err);
            });
          }

          // Stop the temporary camera stream audio (we use the original)
          cameraStream.getAudioTracks().forEach(track => track.stop());
        }

        toast.info('Screen sharing stopped');
      }
    } catch (error) {
      console.error('Error toggling screen share:', error);
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        toast.error('Screen sharing permission denied');
      } else if (error.name === 'NotSupportedError') {
        toast.error('Screen sharing not supported in this browser');
      } else {
        toast.error('Failed to toggle screen sharing');
      }
      setIsScreenSharing(false);
    }
  };

  // Toggle fullscreen
  const toggleFullscreen = () => {
    if (!containerRef.current) return;

    if (!isFullscreen) {
      if (containerRef.current.requestFullscreen) {
        containerRef.current.requestFullscreen();
      } else if (containerRef.current.webkitRequestFullscreen) {
        containerRef.current.webkitRequestFullscreen();
      } else if (containerRef.current.msRequestFullscreen) {
        containerRef.current.msRequestFullscreen();
      }
    } else {
      if (document.exitFullscreen) {
        document.exitFullscreen();
      } else if (document.webkitExitFullscreen) {
        document.webkitExitFullscreen();
      } else if (document.msExitFullscreen) {
        document.msExitFullscreen();
      }
    }
  };

  // Enumerate audio devices
  const enumerateAudioDevices = async () => {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const microphones = devices.filter(d => d.kind === 'audioinput');
      const speakers = devices.filter(d => d.kind === 'audiooutput');

      setAvailableMicrophones(microphones);
      setAvailableSpeakers(speakers);

      // Set current devices
      if (localStream) {
        const audioTracks = localStream.getAudioTracks();
        if (audioTracks.length > 0) {
          const settings = audioTracks[0].getSettings();
          if (settings.deviceId) {
            setCurrentMicrophoneId(settings.deviceId);
          }
        }
      }

      // For speakers, use default if available
      if (speakers.length > 0 && !currentSpeakerId) {
        // Try to get default speaker from audio element if available
        setCurrentSpeakerId(speakers[0].deviceId || 'default');
      }

      return { microphones, speakers };
    } catch (error) {
      console.error('Error enumerating audio devices:', error);
      return { microphones: [], speakers: [] };
    }
  };

  // Switch microphone
  const switchMicrophone = async (deviceId) => {
    try {
      if (!localStream) return;

      const newStream = await navigator.mediaDevices.getUserMedia({
        audio: { deviceId: { exact: deviceId } },
        video: callType === 'video' ? (currentCameraId ? { deviceId: { exact: currentCameraId } } : true) : false
      });

      // Replace audio tracks
      const audioTrack = newStream.getAudioTracks()[0];
      const sender = peerRef.current?._pc?.getSenders()?.find(s =>
        s.track && s.track.kind === 'audio'
      );

      if (sender && peerRef.current) {
        await sender.replaceTrack(audioTrack);
      }

      // Update local stream
      localStream.getAudioTracks().forEach(track => track.stop());
      localStream.addTrack(audioTrack);

      // Stop video track from new stream (we only needed audio)
      if (callType === 'video') {
        newStream.getVideoTracks().forEach(track => track.stop());
      }

      setCurrentMicrophoneId(deviceId);
      toast.success('Microphone switched');
    } catch (error) {
      console.error('Error switching microphone:', error);
      toast.error('Failed to switch microphone');
    }
  };

  // Switch speaker (audio output)
  const switchSpeaker = async (deviceId) => {
    try {
      // Set sink ID for audio output (if supported)
      if (remoteAudioRef.current && remoteAudioRef.current.setSinkId) {
        await remoteAudioRef.current.setSinkId(deviceId);
        setCurrentSpeakerId(deviceId);
        toast.success('Speaker switched');
      } else if (remoteVideoRef.current && remoteVideoRef.current.setSinkId) {
        await remoteVideoRef.current.setSinkId(deviceId);
        setCurrentSpeakerId(deviceId);
        toast.success('Speaker switched');
      } else {
        toast.info('Speaker switching not supported in this browser');
      }
    } catch (error) {
      console.error('Error switching speaker:', error);
      toast.error('Failed to switch speaker');
    }
  };

  // Monitor connection quality
  useEffect(() => {
    if (!peerRef.current || !peerRef.current._pc || callState !== 'active') return;

    const checkConnectionQuality = async () => {
      try {
        if (!peerRef.current || !peerRef.current._pc || isEndingCallRef.current) return;
        const stats = await peerRef.current._pc.getStats();
        let packetsLost = 0;
        let packetsReceived = 0;
        let rtt = 0;
        let jitter = 0;

        stats.forEach(report => {
          if (report.type === 'inbound-rtp' || report.type === 'outbound-rtp') {
            if (report.packetsLost !== undefined) {
              packetsLost += report.packetsLost || 0;
            }
            if (report.packetsReceived !== undefined) {
              packetsReceived += report.packetsReceived || 0;
            }
            if (report.jitter !== undefined) {
              jitter += report.jitter || 0;
            }
          }
          if (report.type === 'candidate-pair' && report.selected) {
            if (report.currentRoundTripTime !== undefined) {
              rtt = report.currentRoundTripTime * 1000; // Convert to ms
            }
          }
        });

        // Determine quality based on metrics
        let quality = 'good';
        if (rtt < 100 && packetsLost === 0 && jitter < 30) {
          quality = 'excellent';
        } else if (rtt < 200 && packetsLost < 5 && jitter < 50) {
          quality = 'good';
        } else if (rtt < 300 && packetsLost < 10 && jitter < 100) {
          quality = 'fair';
        } else {
          quality = 'poor';
        }

        setConnectionQuality(quality);
      } catch (error) {
        // Silently ignore errors during teardown
        if (!isEndingCallRef.current && peerRef.current?._pc) {
          console.error('Error checking connection quality:', error);
        }
      }
    };

    const qualityInterval = setInterval(checkConnectionQuality, 5000); // Check every 5 seconds

    return () => clearInterval(qualityInterval);
  }, [callState, peerRef.current]);

  // Handle fullscreen changes
  useEffect(() => {
    const handleFullscreenChange = () => {
      setIsFullscreen(!!(
        document.fullscreenElement ||
        document.webkitFullscreenElement ||
        document.msFullscreenElement
      ));
    };

    document.addEventListener('fullscreenchange', handleFullscreenChange);
    document.addEventListener('webkitfullscreenchange', handleFullscreenChange);
    document.addEventListener('msfullscreenchange', handleFullscreenChange);

    return () => {
      document.removeEventListener('fullscreenchange', handleFullscreenChange);
      document.removeEventListener('webkitfullscreenchange', handleFullscreenChange);
      document.removeEventListener('msfullscreenchange', handleFullscreenChange);
    };
  }, []);

  // Enumerate audio devices when call becomes active
  useEffect(() => {
    if (callState === 'active' && localStream) {
      enumerateAudioDevices();
    }
  }, [callState, localStream]);

  return {
    callState,
    incomingCall,
    localStream,
    remoteStream,
    isMuted,
    isVideoEnabled,
    remoteIsMuted,
    remoteVideoEnabled,
    callDuration,
    activeCall,
    localVideoRef,
    remoteVideoRef,
    remoteAudioRef,
    containerRef,
    availableCameras,
    currentCameraId,
    isScreenSharing,
    remoteIsScreenSharing,
    cameraStreamDuringScreenShare,
    screenShareStream: screenShareStreamRef.current,
    isFullscreen,
    connectionQuality,
    availableMicrophones,
    availableSpeakers,
    currentMicrophoneId,
    currentSpeakerId,
    initiateCall,
    acceptCall,
    rejectCall,
    endCall,
    toggleMute,
    toggleVideo,
    switchCamera,
    toggleScreenShare,
    toggleFullscreen,
    enumerateCameras,
    enumerateAudioDevices,
    switchMicrophone,
    switchSpeaker
  }; // End of return
}; // End of useCall

export default useCall;
